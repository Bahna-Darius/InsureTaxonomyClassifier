{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import Libraries",
   "id": "7a80ca85983e79"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T17:08:40.100882Z",
     "start_time": "2025-04-01T17:08:40.094654Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import spacy\n"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:08:40.212315Z",
     "start_time": "2025-04-01T17:08:40.126273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "company_data = pd.read_csv('../data/input/ml_insurance_challenge.csv')\n",
    "taxonomy_data = pd.read_csv('../data/input/insurance_taxonomy.csv')"
   ],
   "id": "dfb8e24265b7fa1a",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:08:40.232812Z",
     "start_time": "2025-04-01T17:08:40.219515Z"
    }
   },
   "cell_type": "code",
   "source": "company_data.isnull().sum()      # Missing Data",
   "id": "dc5355eb68abcd86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description      12\n",
       "business_tags     0\n",
       "sector           27\n",
       "category         27\n",
       "niche             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have missing data, we have two options:\n",
    "\n",
    "(a) Remove rows with missing values\n",
    "\n",
    "(b) Fill missing data with a default value\n",
    "\n",
    "I delete the missing data because i don't want to fill in with wrong information (being a small number of data we don't lose a large amount of information)"
   ],
   "id": "3fb7d2e3115df4ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:08:40.294277Z",
     "start_time": "2025-04-01T17:08:40.281159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "company_data.dropna(inplace=True)\n",
    "company_data.isnull().sum()"
   ],
   "id": "247d3c7adc500092",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description      0\n",
       "business_tags    0\n",
       "sector           0\n",
       "category         0\n",
       "niche            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eliminate noise (special characters, stopwords & apply Lemmatizer( \"running\", \"ran\", \"runs\" -> \"run\")) that does not bring significant information for classification.",
   "id": "ae866ce21cb30530"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:08:40.388841Z",
     "start_time": "2025-04-01T17:08:40.383697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Download Resource:\n",
    "# # nltk.download('stopwords')\n",
    "# # nltk.download('wordnet')\n",
    "# # nltk.download('averaged_perceptron_tagger_eng')\n",
    "#\n",
    "#\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "#\n",
    "#\n",
    "# def get_wordnet_pos(word):\n",
    "#     tag = pos_tag([word])[0][1][0].upper()\n",
    "#     tag_dict = {\n",
    "#         \"J\": wordnet.ADJ,\n",
    "#         \"N\": wordnet.NOUN,\n",
    "#         \"V\": wordnet.VERB,\n",
    "#         \"R\": wordnet.ADV\n",
    "#     }\n",
    "#\n",
    "#     if word.endswith(\"ing\"):\n",
    "#         return wordnet.VERB\n",
    "#\n",
    "#     return tag_dict.get(tag, wordnet.NOUN)\n",
    "#\n",
    "#\n",
    "# def lemmatize_text(text):\n",
    "#     words = text.split()\n",
    "#     return ' '.join(\n",
    "#         [lemmatizer.lemmatize(word=word, pos=get_wordnet_pos(word)) for word in words]\n",
    "#     )\n",
    "#\n",
    "#\n",
    "# def clean_text(text):\n",
    "#     if isinstance(text, str):\n",
    "#         text = text.lower()\n",
    "#         text = re.sub(r'[^a-z\\s]', '', text)\n",
    "#         words = text.split()\n",
    "#         words = [word for word in words if word not in stop_words]\n",
    "#         text = ' '.join(words)\n",
    "#         lemmatized_text = lemmatize_text(text)\n",
    "#         return lemmatized_text\n",
    "#\n",
    "#     return ''"
   ],
   "id": "a8b07862322e3e9f",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:08:40.591748Z",
     "start_time": "2025-04-01T17:08:40.587794Z"
    }
   },
   "cell_type": "code",
   "source": "# company_data['clean_description'] = company_data['description'].apply(clean_text)",
   "id": "c1d6bb6c9217d00a",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:11:03.317801Z",
     "start_time": "2025-04-01T17:08:40.733154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatize_text_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "\n",
    "company_data['clean_description'] = company_data['description'].apply(lemmatize_text_spacy)"
   ],
   "id": "b4bcb5624a67582b",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:15:22.227960Z",
     "start_time": "2025-04-01T17:15:22.222595Z"
    }
   },
   "cell_type": "code",
   "source": "company_data.iloc[0, 5]",
   "id": "60dc6c67cc7d7f46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'welchcivil civil engineering construction company specialize design build utility network connection UK offer multi utility solution combine electricity gas water fibre optic installation single contract design engineer team capable design electricity water gas network exist network connection point meter location development project management reinforcement diversion provide custom connection solution account exist asset maximize usage trench meet project deadline welchcivil considerable expertise instal gas electricity connection variety market category include residential commercial industrial project'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:11:03.435415Z",
     "start_time": "2025-04-01T17:11:03.428156Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c41501d46999a019",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T17:11:03.493705Z",
     "start_time": "2025-04-01T17:11:03.485235Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3735cc843d4ae1d6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
